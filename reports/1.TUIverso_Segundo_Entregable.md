

![Logo de TUI](../data/imagenes/652884.webp)

# **<span style="color:red">TUIverso</span>**

*<span style="color:#00BFFF">Explorando el universo de destinos con datos y tendencias tur√≠sticas</span>*

# üìä Segundo Entregable ‚Äì ETL y Preprocesamiento 

üìÖ *Fecha l√≠mite: 19/05/2025*

---

## üìå Descripci√≥n General  

En este segundo entregable se ha implementado el pipeline **ETL** para el proyecto **TUIverso**, realizando la extracci√≥n de datos de diferentes fuentes, su transformaci√≥n y carga en una base de datos PostgreSQL. Adem√°s, se documenta el proceso completo y se entrega un dataset limpio y estructurado listo para el an√°lisis.

---

## üì• Fase de Extracci√≥n

Se han obtenido datos desde dos fuentes principales:
- **P√°gina web de [TUI](https://es.tui.com/)**: mediante scraping con **BeautifulSoup**, para extraer los destinos tur√≠sticos disponibles para clientes espa√±oles.
- **API de [Dataestur](https://www.dataestur.es/apidata/)**: descarga de un CSV con los destinos m√°s visitados por los residentes de Espa√±a.

El scraping se ejecutaba diariamente para actualizar el hist√≥rico de datos.

**Herramientas utilizadas**: `pandas`, `requests`, `numpy`, `python`, `jupyter`, `.env`

### üìÇ Ficheros generados  
Guardados en [`data_raw`](../data/data_raw)

| Fichero                         | Descripci√≥n |
|:--------------------------------|:------------|
| [`escrapeo_continentes.pkl`](../data/data_raw/escrapeo_continentes.pkl)     | Informaci√≥n de los continentes de cada viaje desde TUI. |
| [`escrapeo_destinos.pkl`](../data/data_raw/escrapeo_destinos.pkl)       | Listado de pa√≠ses con viajes disponibles. |
| [`escrapeo_total_viajes.pkl`](../data/data_raw/escrapeo_total_viajes.pkl)    | Detalles completos de cada viaje. |
| [`escrapeo_opciones_viajes.pkl`](../data/data_raw/escrapeo_opciones_viajes.pkl) | Detalle completo de cada opcion de viaje. |
| [`turismo_emisor_ccaa_pais.csv`](../data/data_raw/turismo_emisor_ccaa_pais.csv)  | Datos de turistas y pernoctaciones por pa√≠s desde [Dataestur](https://www.dataestur.es/apidata/). |

---

## üîÑ Fase de Transformaci√≥n

Se normalizaron y estandarizaron los datos: nombres de pa√≠ses, continentes, itinerarios, etc.  
Se realiz√≥ limpieza de duplicados y correcci√≥n de pa√≠ses ficticios como ‚ÄúCaribe‚Äù utilizando la **API de [OpenCage](https://opencagedata.com/api)** para geolocalizar correctamente cada ciudad.

**Herramientas utilizadas**: `pandas`, `requests`, `numpy`, `dotenv`, `sys`

### üìÇ Ficheros generados  
Guardados en [`data/data_transform`](../data/data_transform)

| Fichero                                      | Descripci√≥n |
|:---------------------------------------------|:------------|
| [`itinerarios_ciudades_procesados_1.pkl`](../data/data_transform/itinerarios_ciudades_procesados_1.pkl)        | Desglose de itinerarios por ciudad. |
| [`continentes_escrapeados_procesados.pkl`](../data/data_transform/continentes_escrapeados_procesados.pkl)     | Asociaci√≥n corregida de pa√≠ses a continentes. |
| [`total_viajes_procesados.pkl`](../data/data_transform/total_viajes_procesados.pkl)              | Unificaci√≥n de viajes y opciones, limpieza de duplicados. |
| [`turismo_emisor_ccaa_pais.csv`](../data/data_transform/turismo_emisor_ccaa_pais_procesado.csv)             | Datos de Dataestur limpios y normalizados. |

---

## üóÑÔ∏è Fase de Carga en Base de Datos

Se cre√≥ una BBDD llamada **TUIverso** con la siguiente estructura [`ERD`](Esquema_ERD_TUIverso.png)

**Scripts preparados para cargar solo datos nuevos y actualizar viajes existentes.**

**Herramientas utilizadas**: `pandas`, `numpy`, `psycopg2`

### üìä Tablas creadas

| Tabla                        | Descripci√≥n |
|:----------------------------|:------------|
| `pais_destino`               | Registro √∫nico de cada pa√≠s con su continente asociado. |
| `itinerario`                 | Registro √∫nico de cada itinerario disponible. |
| `ciudad`                     | Registro √∫nico de cada ciudad de los itinerarios. |
| `ciudad_itinerario`          | Relaci√≥n N:M entre ciudades e itinerarios. |
| `viaje`                      | Registro √∫nico por URL de viaje, con nombre, duraci√≥n, itinerario y estado activo. |
| `precio_viaje`               | Precio diario de cada viaje extra√≠do de la web. |
| `combinacion_destino_viaje`  | Relaci√≥n N:M entre pa√≠ses y viajes. |
| `turismo_emisor`             | Datos de Dataestur limpios y normalizados. |

---

## üìå Problemas Encontrados

Durante el desarrollo del pipeline ETL para el proyecto **TUIverso** se han presentado diversos retos que se detallan a continuaci√≥n:

- **Datos inconsistentes en nombres de pa√≠ses y continentes**  
  Los datos procedentes del webscraping y de la API de Dataestur conten√≠an nombres de pa√≠ses, continentes e itinerarios escritos de forma diferente. Fue necesario normalizarlos y estandarizarlos para unificarlos correctamente.

- **Contenidos ficticios y continentes no oficiales**  
  La web de TUI inclu√≠a continentes ficticios como "Caribe" o "Oriente Medio" que no permiten una correcta localizaci√≥n geogr√°fica. Se resolvi√≥ consultando la API de **OpenCage** para obtener la localizaci√≥n oficial de cada pa√≠s y su continente.

- **Viajes duplicados en diferentes pa√≠ses**  
  Algunos viajes aparec√≠an en m√°s de un pa√≠s porque su itinerario pasaba por varias localizaciones. Esto requer√≠a gestionar correctamente las relaciones entre pa√≠ses, itinerarios y viajes para evitar duplicidades en base de datos.

- **URLs de viaje inestables**  
  Algunos viajes manten√≠an su URL pero cambiaban de nombre o precio con el tiempo, mientras otros cambiaban la URL manteniendo el nombre. Se resolvi√≥ utilizando la URL como identificador √∫nico y actualizando el resto de campos seg√∫n la √∫ltima extracci√≥n.

- **Geolocalizaci√≥n de ciudades no fiables**  
  Se detectaron itinerarios que compart√≠an ciudades con el mismo nombre en diferentes pa√≠ses. Fue necesario validar cada ciudad mediante API para obtener su pa√≠s correcto y evitar errores de asignaci√≥n.

- **Evitar duplicados en la BBDD**  
  Para evitar cargar datos duplicados en la base de datos con registros ya existentes, se programaron scripts para insertar √∫nicamente los datos nuevos y actualizar registros existentes seg√∫n fuera necesario.

---

## üìì Notebooks de trabajo  
Guardados en [`notebooks`](../notebooks)

| Notebook                  | Descripci√≥n |
|:--------------------------|:------------|
| [`api.ipynb`](../notebooks/api.ipynb)                | Extracci√≥n de datos desde la API de Dataestur. |
| [`escrapeo_final.ipynb`](../notebooks/escrapeo_final.ipynb)    | Scraping de datos desde la web de TUI. |
|[`transformaci√≥n.ipynb`](../notebooks/transformaci√≥n.ipynb)    | Transformaci√≥n y normalizaci√≥n de datos. |
| [`carga.ipynb`](../notebooks/carga.ipynb)             | Carga de datos a la base de datos. |

---

## üìù Scripts de apoyo  
Guardados en [`src/etl`](../src/etl)

| Script         | Descripci√≥n |
|:----------------|:------------|
| [`extract.py`](../src/etl/extract.py)     | Funciones de extracci√≥n desde web y API. Ejecuta `escrapeo_total()`. |
| [`transform.py`](../src/etl/transform.py)   | Funciones de transformaci√≥n. Ejecuta `transformacion_total_1()`. |
| [`load.py`](../src/etl/load.py)       | Funciones para la carga a BBDD. Ejecuta `carga_total()`. |
| [`main.py`](../src/etl/main.py)        | Orquesta las funciones anteriores para ejecutar el ETL completo. |

---

## üìà Pr√≥ximos pasos

- Estructurar de forma m√°s clara el c√≥digo en m√≥dulos reutilizables.
- Analizar con m√°s detalle los cambios en los viajes de la web.
- Verificar de forma exhaustiva que todas las ciudades tienen su pa√≠s correctamente asociado.

---
